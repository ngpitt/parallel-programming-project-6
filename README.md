Eric Fjosee, Luke Jones, Jeffery Lewis, Nicholas Pitt

3/28/14

#Benchmarking Suite Project Summary

Our project will focus on running various tests on the Blue Gene/Q. These tests will focus on networking throughput with regard to node population via the mapping argument as well as thread communication and thread placement (KSR1 paper). We will also be experimenting with various types of mutexes (MCS paper) and how each type performs in comparison to the Blue Gene/Q’s hardware transactional memory (HTM). Since the Blue Gene/Q is the first system to implement HTM in hardware and will thus not consume resources otherwise used by the application, we expect HTM to outperform all the various types of software level locking and thus greatly improve performance of thread synchronization. Software locking we will be implementing includes test-and-set locks, ticket locks, array-based queuing locks, and list-based queuing locks.

To stress the Blue Gene/Q’s networking throughput, we will be relying on collective commands coupled with parallel IO. Possible schemes include running various collective commands to compute a result, writing the result to the file system in parallel, computing the result again, and comparing it to the previous answer stored on the file system, again in parallel. This will ensure that we test parallel reading and writing in addition to the reliability of the calculation. We also plan to stress the communication channels within the node by implementing a light-weight thread communication scheme within nodes, each node having one rank for global communication. While we do not expect thread placement within a node to have an effect on execution time of the program nor know how to accomplish it, we will be attempting to test thread placement as well.

With regard to thread communication, we will also be gathering cache statistics available from the Blue Gene/Q. The application will be implemented such that the computational problem can be scaled, either to fit in cache, or overflow into main memory. This will enable us to get concrete measurements of the efficiency of running in cache over main memory as well as the best types of thread communication to use. Ultimately, we will be looking for an algorithm which maximizes cache hits, both when run entirely in cache or overflowing into main memory. This will require additional research into how these statistics are accessed.
